{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Presto in EarthEngine\n",
        "\n",
        "**Authors**: Ivan Zvonkov, Gabriel Tseng\n",
        "\n",
        "**Description**:\n",
        "1. Loads default Presto model.\n",
        "2. Deploys default model to Vertex AI.\n",
        "\n",
        "Inspired by: https://github.com/google/earthengine-community/blob/master/guides/linked/Earth_Engine_PyTorch_Vertex_AI.ipynb\n",
        "\n",
        "**Running this demo may incur charges to your Google Cloud Account!**"
      ],
      "metadata": {
        "id": "_SVA9v_JTq_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "hzb1bwgTUZU0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuoEjld3TTLO"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "\n",
        "import ee\n",
        "import google\n",
        "\n",
        "# REPLACE WITH YOUR CLOUD PROJECT!\n",
        "PROJECT = 'presto-deployment'\n",
        "\n",
        "# Authenticate the notebook.\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Authenticate to Earth Engine.\n",
        "credentials, _ = google.auth.default()\n",
        "ee.Initialize(credentials, project=PROJECT, opt_url='https://earthengine-highvolume.googleapis.com')\n",
        "\n",
        "# Set the gcloud project for Vertex AI deployment.\n",
        "!gcloud config set project {PROJECT}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nasaharvest/presto.git"
      ],
      "metadata": {
        "id": "MRGjYjltsm6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load model"
      ],
      "metadata": {
        "id": "P1zGbf2KIhLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/presto"
      ],
      "metadata": {
        "id": "WIJKe-vAs6__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from single_file_presto import Presto\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "UKgCxBNnYJIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Presto.construct()\n",
        "model.load_state_dict(torch.load(\"data/default_model.pt\", map_location=device))\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "uF72fMTE1fIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check\n",
        "\n",
        "# from presto.eval import CropHarvestEval\n",
        "\n",
        "# togo_eval = CropHarvestEval(\"Togo\", ignore_dynamic_world=False, num_timesteps=12, seed=0)\n",
        "# results = togo_eval.finetuning_results(model, model_modes=[\"Regression\"])\n",
        "# results\n",
        "\n",
        "# batch_size = 8\n",
        "# X_np, dw_np, latlons_np, y_np = togo_eval.dataset.as_array(num_samples=batch_size)\n",
        "# month_np = np.array([togo_eval.dataset.start_month] * batch_size)"
      ],
      "metadata": {
        "id": "HE5KeE4G17fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct input manually\n",
        "batch_size = 256\n",
        "\n",
        "X_tensor = torch.zeros([batch_size, 12, 17])\n",
        "latlons_tensor = torch.zeros([batch_size, 2])\n",
        "\n",
        "dw_empty = torch.full([batch_size, 12], 9, device=device).long()\n",
        "month_tensor = torch.full([batch_size], 1, device=device)\n",
        "\n",
        "# [0   1   2   3   4   5   6   7   8   9    10   11   12    13      14    16     17  ]\n",
        "# [VV, VH, B2, B3, B4, B5, B6, B7, B8, B8A, B11, B12, temp, precip, elev, slope, NDVI]\n",
        "mask = torch.zeros(X_tensor.shape, device=device).float()"
      ],
      "metadata": {
        "id": "hDKqqzi9F7T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    preds = model.encoder(\n",
        "        x=X_tensor,\n",
        "        dynamic_world=dw_empty,\n",
        "        latlons=latlons_tensor,\n",
        "        mask=mask,\n",
        "        month=month_tensor\n",
        "    )\n",
        "preds"
      ],
      "metadata": {
        "id": "jQVWkY1nBClT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy to Vertex AI"
      ],
      "metadata": {
        "id": "5v7gJoysFTsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "id": "GjB3wVLDGbav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchserve torch-model-archiver -q\n",
        "!mkdir pytorch_model"
      ],
      "metadata": {
        "id": "Xz53_ow1ZWql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ts.torch_handler.base_handler import BaseHandler\n",
        "\n",
        "# Make model torchscriptable\n",
        "example_kwargs = {\n",
        "    'x': X_tensor,\n",
        "    'dynamic_world': dw_empty,\n",
        "    'latlons': latlons_tensor,\n",
        "    'mask': mask,\n",
        "    'month': month_tensor\n",
        "}\n",
        "sm = torch.jit.trace(model.encoder, example_kwarg_inputs=example_kwargs)\n",
        "\n",
        "!mkdir -p pytorch_model\n",
        "sm.save('pytorch_model/model.pt')"
      ],
      "metadata": {
        "id": "nFRvUVkHowKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jit_model = torch.jit.load('pytorch_model/model.pt')\n",
        "jit_model(**example_kwargs).shape"
      ],
      "metadata": {
        "id": "cYuSPOyp1A0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile pytorch_model/custom_handler.py\n",
        "\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "from ts.torch_handler.base_handler import BaseHandler\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "version = \"v27\"\n",
        "batch_size = 256\n",
        "\n",
        "def printh(text):\n",
        "    print(f\"HANDLER {version}: {text}\")\n",
        "\n",
        "class ClassifierHandler(BaseHandler):\n",
        "\n",
        "    def inference(self, data):\n",
        "        printh(\"inference begin\")\n",
        "\n",
        "        # Data shape: [ num_pixels, composite_bands, 1, 1 ]\n",
        "        data = data[:, :, 0, 0]\n",
        "        printh(f\"data shape {data.shape}\")\n",
        "\n",
        "        num_bands = 17\n",
        "        printh(f\"num_bands {num_bands}\")\n",
        "\n",
        "        # Subtract first two latlon\n",
        "        num_timesteps = (data.shape[1] - 2) // num_bands\n",
        "        printh(f\"num_timesteps {num_timesteps}\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            batches = torch.split(data, batch_size, dim=0)\n",
        "\n",
        "            # month: An int or torch.Tensor describing the first month of the instances being passed. If an int, all instances in the batch are assumed to have the same starting month.\n",
        "            month_tensor = torch.full([batch_size], 3, device=self.device)\n",
        "            printh(f\"month: 3\")\n",
        "\n",
        "            # dynamic_world: torch.Tensor of shape [batch_size, num_timesteps]. If no Dynamic World classes are available, this tensor should be filled with the value DynamicWorld2020_2021.class_amount (i.e. 9), in which case it is ignored.\n",
        "            dw_empty = torch.full([batch_size, num_timesteps], 9, device=self.device).long()\n",
        "            printh(f\"dw {dw_empty[0]}\")\n",
        "\n",
        "            # mask: An optional torch.Tensor of shape [batch_size, num_timesteps, bands]. mask[i, j, k] == 1 means x[i, j, k] is considered masked. If the mask is None, no values in x are ignored.\n",
        "            mask = torch.zeros((batch_size, num_timesteps, num_bands), device=self.device).float()\n",
        "            printh(f\"mask sample one timestep: {mask[0, 0]}\")\n",
        "\n",
        "            preds = []\n",
        "            for batch in batches:\n",
        "\n",
        "                padding = 0\n",
        "                if batch.shape[0] < batch_size:\n",
        "                    padding = batch_size - batch.shape[0]\n",
        "                    batch = torch.cat([batch, torch.zeros([padding, batch.shape[1]], device=self.device)])\n",
        "\n",
        "                # x: torch.Tensor of shape [batch_size, num_timesteps, bands] where bands is described by NORMED_BANDS.\n",
        "                X_tensor = batch[:, 2:]\n",
        "                printh(f\"X {X_tensor.shape}\")\n",
        "\n",
        "                X_tensor_reshaped = X_tensor.reshape(batch_size, num_timesteps, num_bands)\n",
        "                printh(f\"X sample one timestep: {X_tensor_reshaped[0, 0]}\")\n",
        "\n",
        "                # latlons: torch.Tensor of shape [batch_size, 2] describing the latitude and longitude of each input instance.\n",
        "                latlons_tensor = batch[:, :2]\n",
        "\n",
        "                # Shapes\n",
        "                printh(\"SHAPES\")\n",
        "                printh(f\"X {X_tensor_reshaped.shape}\")\n",
        "                printh(f\"dw {dw_empty.shape}\")\n",
        "                printh(f\"latlons {latlons_tensor.shape}\")\n",
        "                printh(f\"mask {mask.shape}\")\n",
        "                printh(f\"month {month_tensor.shape}\")\n",
        "\n",
        "                pred = self.model(\n",
        "                    x=X_tensor_reshaped,\n",
        "                    dynamic_world=dw_empty,\n",
        "                    latlons=latlons_tensor,\n",
        "                    mask=mask,\n",
        "                    month=month_tensor\n",
        "                )\n",
        "                pred_np = np.expand_dims(pred.numpy(), axis=[1,2])\n",
        "                if padding == 0:\n",
        "                    preds.append(pred_np[:])\n",
        "                else:\n",
        "                    preds.append(pred_np[:-padding])\n",
        "\n",
        "        [printh(f\"{p.shape}\") for p in preds]\n",
        "        preds = np.concatenate(preds)\n",
        "        printh(f\"preds shape {preds.shape}\")\n",
        "        return preds\n",
        "\n",
        "    def handle(self, data, context):\n",
        "        self.context = context\n",
        "        printh(f\"handle begin\")\n",
        "        input_tensor = self.preprocess(data)\n",
        "        printh(f\"input_tensor shape {input_tensor.shape}\")\n",
        "        pred_out = self.inference(input_tensor)\n",
        "        return self.postprocess(pred_out)"
      ],
      "metadata": {
        "id": "htq2Ac95FJlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import pytorch_model\n",
        "from pytorch_model.custom_handler import ClassifierHandler\n",
        "importlib.reload(pytorch_model.custom_handler)\n",
        "\n",
        "from pytorch_model.custom_handler import ClassifierHandler\n",
        "\n",
        "# Test output\n",
        "data = torch.zeros([713, 206, 1, 1])\n",
        "handler = ClassifierHandler()\n",
        "handler.model = jit_model\n",
        "preds = handler.handle(data=data, context=None)"
      ],
      "metadata": {
        "id": "a3Dgq5Ob5b1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!torch-model-archiver -f \\\n",
        "  --model-name model \\\n",
        "  --version 1.0 \\\n",
        "  --serialized-file 'pytorch_model/model.pt' \\\n",
        "  --handler 'pytorch_model/custom_handler.py' \\\n",
        "  --export-path pytorch_model/"
      ],
      "metadata": {
        "id": "90TXNAnfF-TD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "version = \"v27\"\n",
        "MODEL_DIR = f'gs://presto-models/default_v2025_04_10_{version}'\n",
        "!gsutil cp -r pytorch_model {MODEL_DIR}"
      ],
      "metadata": {
        "id": "n8m9UBy3GEvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REGION = 'us-central1'\n",
        "MODEL_NAME = f'model_{version}'\n",
        "CONTAINER_IMAGE = 'us-docker.pkg.dev/vertex-ai/prediction/pytorch-cpu.2-4:latest'\n",
        "ENDPOINT_NAME = 'vertex-pytorch-presto-endpoint'\n",
        "\n",
        "!gcloud ai models upload \\\n",
        "  --artifact-uri={MODEL_DIR} \\\n",
        "  --project={PROJECT} \\\n",
        "  --region={REGION} \\\n",
        "  --container-image-uri={CONTAINER_IMAGE} \\\n",
        "  --description={MODEL_NAME} \\\n",
        "  --display-name={MODEL_NAME} \\\n",
        "  --model-id={MODEL_NAME}\n",
        "\n",
        "# Create endpoint, if endpoint does not exist\n",
        "# !gcloud ai endpoints create \\\n",
        "#   --display-name={ENDPOINT_NAME} \\\n",
        "#   --endpoint-id={ENDPOINT_NAME} \\\n",
        "#   --region={REGION} \\\n",
        "#   --project={PROJECT}\n",
        "\n",
        "!gcloud ai endpoints deploy-model {ENDPOINT_NAME} \\\n",
        "  --project={PROJECT} \\\n",
        "  --region={REGION} \\\n",
        "  --model={MODEL_NAME} \\\n",
        "  --display-name={MODEL_NAME} \\\n",
        "  --machine-type=\"e2-standard-4\"\n",
        "\n",
        "# 21 mintues when issues with server\n",
        "# 4 minutes when it's working"
      ],
      "metadata": {
        "id": "AetRF8dcGraC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}